#!/usr/bin/env python3
"""
å¿«é€Ÿå¼€å§‹æ¼”ç¤º
æ¼”ç¤ºç¯å¢ƒã€åŸºçº¿ç­–ç•¥å’ŒPPOè®­ç»ƒ
"""

import sys
import os
import time

def print_section(title):
    """æ‰“å°ç« èŠ‚æ ‡é¢˜"""
    print("\n" + "=" * 60)
    print(title.center(60))
    print("=" * 60 + "\n")


def demo_environment():
    """æ¼”ç¤ºç¯å¢ƒ"""
    print_section("1. ç¯å¢ƒæ¼”ç¤º")
    
    from src.environment import PlantCareEnv
    
    print("åˆ›å»ºæ¤ç‰©æŠ¤ç†ç¯å¢ƒ...")
    env = PlantCareEnv(config_path="config.yaml")
    
    print(f"âœ… ç¯å¢ƒåˆ›å»ºæˆåŠŸ!")
    print(f"  è§‚å¯Ÿç©ºé—´: {env.observation_space}")
    print(f"  åŠ¨ä½œç©ºé—´: {env.action_space}")
    print(f"  æœ€å¤§æ­¥æ•°: {env.max_steps} (30å¤©)")
    
    print("\nè¿è¡Œä¸€ä¸ªéšæœºepisodeï¼ˆ48å°æ—¶ï¼‰...")
    obs, info = env.reset(seed=42)
    
    for step in range(48):
        action = env.action_space.sample()
        obs, reward, terminated, truncated, info = env.step(action)
        
        if step % 12 == 0:
            print(f"  Hour {step}: Health={obs[4]:.1f}, Moisture={obs[0]:.2%}, Temp={obs[1]:.1f}Â°C")
        
        if terminated or truncated:
            break
    
    print(f"\næœ€ç»ˆçŠ¶æ€:")
    print(f"  å¹³å‡å¥åº·åº¦: {info['avg_health']:.1f}")
    print(f"  æ€»ç”¨æ°´é‡: {info['total_water_used']:.1f} ml")
    
    env.close()
    print("âœ… ç¯å¢ƒæ¼”ç¤ºå®Œæˆ")
    
    input("\næŒ‰Enterç»§ç»­...")


def demo_baselines():
    """æ¼”ç¤ºåŸºçº¿ç­–ç•¥"""
    print_section("2. åŸºçº¿ç­–ç•¥æ¼”ç¤º")
    
    from src.environment import PlantCareEnv
    from src.baselines import FixedSchedulePolicy, ThresholdRulePolicy
    import numpy as np
    
    env = PlantCareEnv(config_path="config.yaml")
    
    # å›ºå®šæ—¶é—´è¡¨
    print("ğŸ“… å›ºå®šæ—¶é—´è¡¨ç­–ç•¥:")
    policy1 = FixedSchedulePolicy(config_path="config.yaml")
    print(f"  æµ‡æ°´æ—¶é—´: {policy1.water_times}")
    print(f"  ç¯å…‰æ—¶é—´: {policy1.lamp_schedule}")
    
    obs, info = env.reset(seed=42)
    for _ in range(24):
        action = policy1.get_action(obs)
        obs, _, _, _, info = env.step(action)
    
    print(f"  24å°æ—¶åå¥åº·åº¦: {obs[4]:.1f}")
    
    # é˜ˆå€¼è§„åˆ™
    print("\nğŸ“Š é˜ˆå€¼è§„åˆ™ç­–ç•¥:")
    policy2 = ThresholdRulePolicy(config_path="config.yaml")
    print(f"  æ¹¿åº¦é˜ˆå€¼: {policy2.moisture_threshold:.1%}")
    print(f"  å…‰ç…§é˜ˆå€¼: {policy2.light_threshold} lux")
    
    obs, info = env.reset(seed=42)
    for _ in range(24):
        action = policy2.get_action(obs)
        obs, _, _, _, info = env.step(action)
    
    print(f"  24å°æ—¶åå¥åº·åº¦: {obs[4]:.1f}")
    
    env.close()
    print("\nâœ… åŸºçº¿ç­–ç•¥æ¼”ç¤ºå®Œæˆ")
    
    input("\næŒ‰Enterç»§ç»­...")


def demo_ppo_training():
    """æ¼”ç¤ºPPOè®­ç»ƒï¼ˆçŸ­æ—¶é—´ï¼‰"""
    print_section("3. PPOè®­ç»ƒæ¼”ç¤º")
    
    print("è¿™å°†æ¼”ç¤ºPPOè®­ç»ƒæµç¨‹ï¼ˆä»…10,000æ­¥ï¼Œçº¦1åˆ†é’Ÿï¼‰")
    print("å®Œæ•´è®­ç»ƒéœ€è¦5,000,000æ­¥ï¼ˆGPUä¸‹çº¦3å°æ—¶ï¼‰")
    print()
    
    response = input("æ˜¯å¦ç»§ç»­? (y/n): ")
    if response.lower() != 'y':
        print("è·³è¿‡è®­ç»ƒæ¼”ç¤º")
        return
    
    from src.agents.train_ppo import train_ppo_agent
    
    print("\nå¼€å§‹è®­ç»ƒ...")
    
    model = train_ppo_agent(
        config_path="config.yaml",
        total_timesteps=10_000,  # ä»…ç”¨äºæ¼”ç¤º
        device="auto",
        save_path="./models/demo/",
        log_path="./logs/demo/",
        seed=42
    )
    
    print("\nâœ… è®­ç»ƒæ¼”ç¤ºå®Œæˆ")
    print("ğŸ’¡ æç¤º: å®Œæ•´è®­ç»ƒè¯·è¿è¡Œ:")
    print("   python src/agents/train_ppo.py --timesteps 5000000")


def demo_visualization():
    """æ¼”ç¤ºå¯è§†åŒ–"""
    print_section("4. å¯è§†åŒ–æ¼”ç¤º")
    
    print("ç”Ÿæˆå¯¹æ¯”å›¾è¡¨...")
    
    from src.utils.visualization import plot_comparison_table, plot_metrics_comparison_bars
    
    # æ¨¡æ‹Ÿç»“æœæ•°æ®
    results = {
        "å›ºå®šæ—¶é—´è¡¨": {
            "avg_health_mean": 60,
            "avg_health_std": 3,
            "total_water_mean": 10200,
            "total_energy_mean": 360000,
            "violations_mean": 120,
            "efficiency_mean": 0.50
        },
        "é˜ˆå€¼è§„åˆ™": {
            "avg_health_mean": 70,
            "avg_health_std": 4,
            "total_water_mean": 8500,
            "total_energy_mean": 320000,
            "violations_mean": 80,
            "efficiency_mean": 0.72
        }
    }
    
    os.makedirs("docs/images", exist_ok=True)
    
    plot_comparison_table(results, save_path="docs/images/demo_table.png")
    plot_metrics_comparison_bars(results, save_path="docs/images/demo_bars.png")
    
    print("âœ… å›¾è¡¨å·²ä¿å­˜åœ¨ docs/images/")
    print("  - demo_table.png")
    print("  - demo_bars.png")


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("æ™ºèƒ½æ¤ç‰©æŠ¤ç†ç³»ç»Ÿ - å¿«é€Ÿå¼€å§‹æ¼”ç¤º".center(60))
    print("=" * 60)
    print()
    print("è¿™ä¸ªæ¼”ç¤ºå°†å¼•å¯¼ä½ äº†è§£é¡¹ç›®çš„ä¸»è¦åŠŸèƒ½:")
    print("  1. æ¤ç‰©æŠ¤ç†ç¯å¢ƒ")
    print("  2. åŸºçº¿ç­–ç•¥")
    print("  3. PPOè®­ç»ƒï¼ˆå¯é€‰ï¼‰")
    print("  4. å¯è§†åŒ–å·¥å…·")
    print()
    
    try:
        demo_environment()
        demo_baselines()
        demo_ppo_training()
        demo_visualization()
        
        print_section("æ¼”ç¤ºå®Œæˆ!")
        print("ğŸ‰ æ­å–œï¼ä½ å·²ç»äº†è§£äº†é¡¹ç›®çš„ä¸»è¦åŠŸèƒ½")
        print()
        print("ä¸‹ä¸€æ­¥:")
        print("  1. è¿è¡Œå®Œæ•´åŸºçº¿å¯¹æ¯”: python run_baseline_comparison.py")
        print("  2. è®­ç»ƒå®Œæ•´PPOæ¨¡å‹: python src/agents/train_ppo.py --timesteps 5000000")
        print("  3. æŸ¥çœ‹TensorBoard: tensorboard --logdir logs/")
        print()
        print("è¯¦ç»†ä¿¡æ¯è¯·æŸ¥çœ‹ README.md")
        print("=" * 60)
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  æ¼”ç¤ºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\n\nâŒ é”™è¯¯: {e}")
        print("è¯·ç¡®ä¿å·²è¿è¡Œ setup.sh å¹¶æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ")


if __name__ == "__main__":
    main()

